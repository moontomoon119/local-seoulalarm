//local-backend\src\scrapers\base-scraper.ts
import axios, { AxiosResponse } from 'axios';
import { Notice, NoticeListItem } from '../types/notice';
import https from 'https'; 
import iconv from 'iconv-lite';

export abstract class BaseScraper {
  protected district: string;
  protected baseUrl: string;
  
  constructor(district: string, baseUrl: string) {
    this.district = district;
    this.baseUrl = baseUrl;
  }

  // ì¶”ìƒ ë©”ì„œë“œë“¤ - ê° ìì¹˜êµ¬ì—ì„œ êµ¬í˜„
  abstract scrapeNoticeList(): Promise<NoticeListItem[]>;
  abstract scrapeNoticeDetail(url: string): Promise<string>;
  abstract parseDate(dateString: string): string;

  // ì¦ë¶„ ìŠ¤í¬ë˜í•‘ì„ ìœ„í•œ ë©”ì„œë“œë“¤ - ìì¹˜êµ¬ë³„ë¡œ ì˜¤ë²„ë¼ì´ë“œ ê°€ëŠ¥
  async scrapeFirstPage(): Promise<Notice[]> {
    console.log(`ğŸ” ${this.district} ì²« í˜ì´ì§€ ìŠ¤í¬ë˜í•‘...`);
    
    // ê¸°ë³¸ êµ¬í˜„: ì²« í˜ì´ì§€ë§Œ ìŠ¤í¬ë˜í•‘í•´ì„œ ê³µì§€ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    const noticeItems = await this.scrapeFirstPageList();
    return this.convertItemsToNotices(noticeItems);
  }
  
  async scrapeAdditionalPages(): Promise<Notice[]> {
    console.log(`ğŸ” ${this.district} ì¶”ê°€ í˜ì´ì§€ ìŠ¤í¬ë˜í•‘...`);
    
    // ê¸°ë³¸ êµ¬í˜„: 2~3í˜ì´ì§€ë§Œ ìŠ¤í¬ë˜í•‘
    const noticeItems = await this.scrapeAdditionalPagesList();
    return this.convertItemsToNotices(noticeItems);
  }
  
  // ì²« í˜ì´ì§€ ëª©ë¡ë§Œ ê°€ì ¸ì˜¤ëŠ” ë©”ì„œë“œ
  async scrapeFirstPageList(): Promise<NoticeListItem[]> {
    // ê¸°ë³¸ êµ¬í˜„: ì²« í˜ì´ì§€ë§Œ ê°€ì ¸ì˜¤ë„ë¡ êµ¬í˜„
    // ìƒì†ë°›ëŠ” í´ë˜ìŠ¤ì—ì„œ ì¬ì •ì˜ ê°€ëŠ¥
    return this.scrapeNoticeList();
  }
  
  // ì¶”ê°€ í˜ì´ì§€ ëª©ë¡ì„ ê°€ì ¸ì˜¤ëŠ” ë©”ì„œë“œ
  async scrapeAdditionalPagesList(): Promise<NoticeListItem[]> {
    // ê¸°ë³¸ êµ¬í˜„: ë¹ˆ ë°°ì—´ ë°˜í™˜
    // ìƒì†ë°›ëŠ” í´ë˜ìŠ¤ì—ì„œ ì¬ì •ì˜ í•„ìš”
    return [];
  }
  
  // NoticeListItem ë°°ì—´ì„ ì™„ì „í•œ Notice ë°°ì—´ë¡œ ë³€í™˜
  private async convertItemsToNotices(items: NoticeListItem[]): Promise<Notice[]> {
    const notices: Notice[] = [];
    
    for (let i = 0; i < items.length; i++) {
      const item = items[i];
      try {
        const content = await this.scrapeNoticeDetail(item.url);
        
        const notice: Notice = {
          district: this.district,
          title: item.title,
          content,
          publishDate: item.publishDate,
          url: item.url,
          category: item.category || 'ì¼ë°˜ê³µê³ '
        };
        
        if (this.validateNotice(notice)) {
          notices.push(notice);
        }
        
        // ìš”ì²­ ê°„ ì§€ì—°
        await this.sleep(1000);
      } catch (error: any) {
        console.error(`âŒ Failed to scrape detail for ${item.title}:`, error.message);
      }
    }
    
    return notices;
  }

  // ê³µí†µ ë©”ì„œë“œë“¤
  protected async fetchWithRetry(
    url: string,
    maxRetries: number = 3,
    encoding: 'utf-8' | 'euc-kr' = 'utf-8'
  ): Promise<string> {
    const agent = new https.Agent({ rejectUnauthorized: false });
  
    // ìì¹˜êµ¬ë³„ Referer ì„¤ì •
    const refererMap: Record<string, string> = {
      'ê°•ë¶êµ¬': 'https://www.gangbuk.go.kr/',
      // ë‹¤ë¥¸ ìì¹˜êµ¬ëŠ” ìƒëµí•˜ê±°ë‚˜ null
    };
  
    const referer = refererMap[this.district] || undefined;
  
    for (let i = 0; i < maxRetries; i++) {
      try {
        console.log(`ğŸ“¡ Fetching: ${url} (attempt ${i + 1})`);
  
        const response: AxiosResponse<ArrayBuffer> = await axios.get(url, {
          responseType: 'arraybuffer',
          timeout: 15000,
          httpsAgent: agent,
          headers: {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)',
            'Accept': 'text/html,application/xhtml+xml',
            'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8',
            ...(referer ? { 'Referer': referer } : {})
          }
        });
  
        if (!response.data) throw new Error('Empty response received');
  
        const buffer = Buffer.from(response.data);
        return encoding === 'euc-kr' ? iconv.decode(buffer, 'euc-kr') : buffer.toString('utf-8');
      } catch (error) {
        const errMsg = error instanceof Error ? error.message : String(error);
        console.warn(`âš ï¸  Attempt ${i + 1} failed:`, errMsg);
  
        if (i === maxRetries - 1) {
          throw new Error(`Failed to fetch ${url} after ${maxRetries} attempts: ${errMsg}`);
        }
  
        await this.sleep(Math.pow(2, i) * 1000);
      }
    }
  
    throw new Error('Unexpected error in fetchWithRetry');
  }
  


  protected sleep(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  protected validateNotice(notice: Notice): boolean {
    return !!(
      notice.title &&
      notice.url &&
      notice.publishDate &&
      notice.district
    );
  }

  protected cleanText(text: string): string {
    return text
      .replace(/\s+/g, ' ')
      .replace(/\n+/g, '\n')
      .trim();
  }

  protected absoluteUrl(relativeUrl: string): string {
    if (relativeUrl.startsWith('http')) {
      return relativeUrl;
    }
    
    const base = new URL(this.baseUrl);
    if (relativeUrl.startsWith('/')) {
      return `${base.protocol}//${base.host}${relativeUrl}`;
    }
    
    return `${this.baseUrl}/${relativeUrl}`;
  }

  // ì „ì²´ ìŠ¤í¬ë˜í•‘ ì›Œí¬í”Œë¡œìš°
  async scrapeAll(): Promise<Notice[]> {
    console.log(`ğŸš€ Starting scrape for ${this.district}...`);
    
    const noticeItems = await this.scrapeNoticeList();
    console.log(`ğŸ“‹ Found ${noticeItems.length} notices`);
    
    const notices: Notice[] = [];
    
    for (let i = 0; i < noticeItems.length; i++) {
      const item = noticeItems[i];
      console.log(`ğŸ“„ Processing ${i + 1}/${noticeItems.length}: ${item.title}`);
      
      try {
        const content = await this.scrapeNoticeDetail(item.url);
        
        const notice: Notice = {
          district: this.district,
          title: item.title,
          content,
          publishDate: item.publishDate,
          url: item.url,
          category: item.category || 'ì¼ë°˜ê³µê³ '
        };

        if (this.validateNotice(notice)) {
          notices.push(notice);
        } else {
          console.log(`âš ï¸  Invalid notice skipped: ${item.title}`);
        }

        // ìš”ì²­ ê°„ ì§€ì—° (ì„œë²„ ë¶€í•˜ ë°©ì§€)
        await this.sleep(1000);
      } catch (error: any) {
        console.error(`âŒ Failed to scrape detail for ${item.title}:`, error.message);
      }
    }

    console.log(`âœ… Scraping completed: ${notices.length} valid notices`);
    return notices;
  }
} 