import * as cheerio from 'cheerio';
import { BaseScraper } from './base-scraper';
import { NoticeListItem } from '../types/notice';

export class MapoScraper extends BaseScraper {
  constructor() {
    super('ë§ˆí¬êµ¬', 'https://www.mapo.go.kr');
  }

  async scrapeNoticeList(): Promise<NoticeListItem[]> {
    const notices: NoticeListItem[] = [];
    const maxPages = 3;

    for (let page = 1; page <= maxPages; page++) {
      const listUrl = `${this.baseUrl}/site/main/nPortal/list?cp=${page}`;
      const html = await this.fetchWithRetry(listUrl);
      const $ = cheerio.load(html);

      $('table tbody tr').each((_, el) => {
        const $row = $(el);
        const titleEl = $row.find('td').eq(2).find('a');
        const title = titleEl.text().trim();
        const relativeUrl = titleEl.attr('href');
        const dateText = $row.find('td').eq(5).text().trim();

        if (title && relativeUrl && dateText) {
          notices.push({
            title,
            url: this.absoluteUrl(relativeUrl),
            publishDate: this.parseDate(dateText),
            category: 'ê³ ì‹œ/ê³µê³ '
          });
        }
      });

      console.log(`ğŸ“‹ ë§ˆí¬êµ¬ ${page}í˜ì´ì§€ì—ì„œ ${notices.length}ê±´`);
      await this.sleep(100);
    }

    return Array.from(new Map(notices.map(n => [n.url, n])).values());
  }

  async scrapeNoticeDetail(url: string): Promise<string> {
    const html = await this.fetchWithRetry(url);
    const $ = cheerio.load(html);

    const contentTd = $('td[colspan="4"]').first();
    if (contentTd.length > 0) {
      return this.cleanText(contentTd.text());
    }

    return $('title').text() || 'ë³¸ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤';
  }

  parseDate(dateString: string): string {
    const cleaned = dateString.replace(/\D/g, '');
    if (cleaned.length === 8) {
      return `${cleaned.slice(0, 4)}-${cleaned.slice(4, 6)}-${cleaned.slice(6, 8)}T00:00:00.000Z`;
    }
    console.warn(`ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨: ${dateString}`);
    return new Date().toISOString();
  }
}
